{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f97c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar Cascade XML file for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fff54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture images and take user input for labels\n",
    "def capture_images(output_path, num_persons=2, max_images_per_person=5):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "\n",
    "    for person_id in range(1, num_persons + 1):\n",
    "        print(f\"\\nCapturing images for Person {person_id}\")\n",
    "        person_image_paths = []\n",
    "        person_labels = []\n",
    "\n",
    "        for image_num in range(1, max_images_per_person + 1):\n",
    "            ret, frame = video_capture.read()\n",
    "            cv2.imshow(\"Captured Image\", frame)\n",
    "\n",
    "            # Take user input for label\n",
    "            label = input(f\"Enter label for Person {person_id}, Image {image_num} or 'exit' to stop: \")\n",
    "\n",
    "            if label.lower() == 'exit':\n",
    "                print(f\"Exiting capturing for Person {person_id}.\")\n",
    "                break\n",
    "\n",
    "            image_path = os.path.join(output_path, f\"{label}_{person_id}_{image_num}.jpg\")\n",
    "            cv2.imwrite(image_path, frame)\n",
    "\n",
    "            person_image_paths.append(image_path)\n",
    "            person_labels.append(label)\n",
    "\n",
    "        all_image_paths.extend(person_image_paths)\n",
    "        all_labels.extend(person_labels)\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return all_image_paths, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655642f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the face recognition model\n",
    "def train_model(csv_filename, image_size=(100, 100), flatten_size=10000):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    images = [cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) for image_path in df[\"ImagePath\"]]\n",
    "    resized_images = [cv2.resize(image, image_size) for image in images]\n",
    "    flattened_images = [image.flatten()[:flatten_size] for image in resized_images]\n",
    "\n",
    "    labels = df[\"Label\"]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    model = SVC(C=1.0, kernel=\"linear\", gamma=\"scale\")\n",
    "    model.fit(flattened_images, encoded_labels)\n",
    "\n",
    "    return model, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recognize faces in real-time\n",
    "def recognize_faces(video_capture, trained_model, label_encoder, rectangle_color=(0, 255, 0), label_color=(255, 255, 0)):\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_roi = gray_frame[y:y+h, x:x+w]\n",
    "            resized_face = cv2.resize(face_roi, (100, 100))\n",
    "            flattened_face = resized_face.flatten()\n",
    "\n",
    "            encoded_label = trained_model.predict([flattened_face])[0]\n",
    "            label = label_encoder.inverse_transform([encoded_label])[0]\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), rectangle_color, 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, label_color, 2)\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"newImage\"\n",
    "csv_filename = \"face_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8095f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Capture images and take user input for labels\n",
    "image_paths, labels = capture_images(output_path, num_persons=2, max_images_per_person=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6797aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Save the captured images and labels to a CSV file\n",
    "df = pd.DataFrame({\"ImagePath\": image_paths, \"Label\": labels})\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the model using the captured images\n",
    "trained_model, label_encoder = train_model(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde98ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Start real-time face recognition using the trained model\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "recognize_faces(video_capture, trained_model, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fbed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
